{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset():\n",
    "    '''The function creates a dataset from audio files in a directory, extracting message ID, audio file\n",
    "    name, and person ID.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        A DataFrame containing information about audio files in the 'AudiosMp3' directory. The DataFrame\n",
    "    has columns 'Id_Mensaje', 'Audio', and 'Id_Persona'.\n",
    "    \n",
    "    '''\n",
    "    files = os.listdir('../audios_modelo/')\n",
    "    \n",
    "    dict = {'Audio': [], 'Id_Persona': []}\n",
    "    for file in files:\n",
    "        dict['Audio'].append(file)\n",
    "        if file[11:-4] == 'Gerard': \n",
    "            dict['Id_Persona'].append(0)\n",
    "        elif file[11:-4] == 'Albert': \n",
    "            dict['Id_Persona'].append(1)\n",
    "        elif file[11:-4] == 'Adria': \n",
    "            dict['Id_Persona'].append(2)\n",
    "        elif file[11:-4] == 'Raul': \n",
    "            dict['Id_Persona'].append(3)\n",
    "        elif file[11:-4] == 'Otros':\n",
    "            dict['Id_Persona'].append(4)\n",
    "            \n",
    "    df = pd.DataFrame(dict)\n",
    "    return df\n",
    "\n",
    "df = createDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Audio</th>\n",
       "      <th>Id_Persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AudioFinal_Adria.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AudioFinal_Albert.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AudioFinal_Gerard.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AudioFinal_Otros.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AudioFinal_Raul.wav</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Audio  Id_Persona\n",
       "0   AudioFinal_Adria.wav           2\n",
       "1  AudioFinal_Albert.wav           1\n",
       "2  AudioFinal_Gerard.wav           0\n",
       "3   AudioFinal_Otros.wav           4\n",
       "4    AudioFinal_Raul.wav           3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipData(data):\n",
    "    '''The `unzipData` function takes a list of tuples, separates the elements into two arrays, and returns\n",
    "    them.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        The `data` parameter is expected to be a list of tuples where each tuple contains two elements. The\n",
    "    first element should be the input data (X) and the second element should be the corresponding target\n",
    "    data (y).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        The `unzipData` function returns two arrays, `X` and `y`, after unzipping the input `data` and\n",
    "    converting them into numpy arrays.\n",
    "    \n",
    "    '''\n",
    "    X, y = zip(*data)\n",
    "    X = np.array(list(X))\n",
    "    y =np.array(list(y))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def removeSilence(audio, silence_threshold = 0.05):\n",
    "    '''The `removeSilence` function removes silent segments from an audio signal based on a specified\n",
    "    silence threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    audio\n",
    "        The `removeSilence` function you provided is designed to remove segments of silence from an audio\n",
    "    signal based on a specified silence threshold. The function takes two parameters:\n",
    "    silence_threshold\n",
    "        The `silence_threshold` parameter in the `removeSilence` function represents the minimum amplitude\n",
    "    value below which a segment of audio is considered as silence. Any audio samples with absolute\n",
    "    values less than this threshold are identified as silence and removed from the audio signal. By\n",
    "    adjusting this threshold, you can control\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        The function `removeSilence` returns the audio signal with silence segments removed based on the\n",
    "    specified silence threshold.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Encontrar los índices de los segmentos de silencio\n",
    "    silence_indices = np.where(np.abs(audio) < silence_threshold)[0]\n",
    "\n",
    "    # Crear una máscara para mantener los segmentos que no son de silencio\n",
    "    mask = np.ones_like(audio, dtype=bool)\n",
    "    mask[silence_indices] = False\n",
    "\n",
    "    # Aplicar la máscara al audio para eliminar los segmentos de silencio\n",
    "    audio_sin_silencio = audio[mask]\n",
    "\n",
    "    if audio_sin_silencio.size == 0:\n",
    "        return audio\n",
    "    return audio_sin_silencio\n",
    "\n",
    "\n",
    "def lowPassFilter(audio, sr, cutoff_freq = 3000):\n",
    "    '''The function `lowPassFilter` applies a low-pass filter to an audio signal in the frequency domain to\n",
    "    remove high-frequency components above a specified cutoff frequency.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    audio\n",
    "        The `audio` parameter is the input audio signal that you want to filter using a low-pass filter. It\n",
    "    is typically represented as a one-dimensional array of audio samples.\n",
    "    sr\n",
    "        The `sr` parameter in the `lowPassFilter` function stands for the sampling rate of the audio\n",
    "    signal. It represents the number of samples taken per second when the audio signal was recorded or\n",
    "    processed. The sampling rate is typically measured in Hertz (Hz).\n",
    "    cutoff_freq\n",
    "        The `cutoff_freq` parameter in the `lowPassFilter` function represents the frequency at which you\n",
    "    want to filter out higher frequencies from the audio signal. Frequencies above the `cutoff_freq`\n",
    "    will be attenuated or removed from the signal, effectively creating a low-pass filter that allows\n",
    "    only\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        The function `lowPassFilter` returns the filtered audio signal in the time domain after applying a\n",
    "    low-pass filter in the frequency domain.\n",
    "    \n",
    "    '''\n",
    "    y_fft = np.fft.fft(audio)\n",
    "\n",
    "    freqs = np.fft.fftfreq(len(audio), 1 / sr)\n",
    "    lowpass_filter = np.abs(freqs) <= cutoff_freq\n",
    "\n",
    "    # Aplicar el filtro pasa bajos multiplicando la señal en el dominio de la frecuencia por el filtro\n",
    "    y_fft_filtered = y_fft * lowpass_filter\n",
    "\n",
    "    # Aplicar la Transformada Inversa de Fourier para obtener la señal filtrada en el dominio del tiempo\n",
    "    y_filtered = np.real(np.fft.ifft(y_fft_filtered))\n",
    "    \n",
    "    return y_filtered\n",
    "\n",
    "\n",
    "def spec(y, sr, spec = 'wavelet'):\n",
    "    '''This Python function generates different types of spectrograms based on the specified type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y\n",
    "        The function `spec` you provided seems to be a spectrogram generator that can produce different\n",
    "    types of spectrograms based on the specified `spec` parameter. However, there are a couple of issues\n",
    "    in the code:\n",
    "    sr\n",
    "        The `sr` parameter in the `spec` function stands for the sampling rate of the audio signal. It\n",
    "    represents the number of samples of audio carried per second, typically measured in Hz (Hertz).\n",
    "    spec, optional\n",
    "        The `spec` function you provided seems to be a spectrogram generator that can produce different\n",
    "    types of spectrograms based on the `spec` parameter provided. The spectrogram types it supports are\n",
    "    'wavelet', 'linear', 'log', 'mel', and 'cqt'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        the spectrogram based on the specified type of spectrogram calculation method (wavelet, linear,\n",
    "    log, mel, or cqt).\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "    if spec == 'linear'  : spectogram = np.abs(librosa.stft(y))\n",
    "\n",
    "    elif spec == 'log' : spectogram = np.abs(librosa.stft(y))\n",
    "    \n",
    "    elif spec == 'mel' : spectogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    \n",
    "    elif spec == 'cqt' : spectogram = np.abs(librosa.cqt(y, sr=sr))\n",
    "    \n",
    "    elif spec == 'wavelet' : spectogram = np.abs(librosa.cqt(y, sr=sr, fmin=librosa.note_to_hz('C1')))\n",
    "    \n",
    "    else: return None\n",
    "    return spectogram\n",
    "\n",
    "\n",
    "\n",
    "def windowing(image, max_size, despl=0):\n",
    "    '''The function `windowing` creates a matrix of windows from an input image by rearranging its columns.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image\n",
    "        The `image` parameter is a 2D numpy array representing an image. Each element in the array\n",
    "    corresponds to a pixel value in the image.\n",
    "    max_size\n",
    "        The `max_size` parameter in the `windowing` function represents the maximum size of the window\n",
    "    matrix that will be created. This parameter determines the number of rows in the window matrix,\n",
    "    while the number of columns will be the same as the number of columns in the input `image` matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        A matrix of windows with the same number of rows as the maximum size provided and the same number\n",
    "    of columns as the input image. Each column of the matrix corresponds to a window extracted from the\n",
    "    input image.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if despl == 0 : windows = np.zeros((max_size, image.shape[0]))  # Crear matriz de ventanas con el mismo número de columnas que la imagen\n",
    "    else: windows = np.zeros((max_size, image.shape[0], despl))\n",
    "    for i in np.arange(0, image.shape[1]):\n",
    "        if i + despl >= image.shape[1]:\n",
    "            break\n",
    "        if despl == 0: windows[i, :] = image[: , i]\n",
    "        else: windows[ i, :, :] = image[: , i :i + despl]\n",
    "    return windows\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rowSpecWindowing(row, specType='mel', despl=0, smoothSpec = False, filter = False, silence = False):\n",
    "    '''The function `compute_rowSpecWindowing` loads an audio file, processes it by removing silence and\n",
    "    smoothing, generates a spectrogram image, and then applies windowing to create smaller segments\n",
    "    along with corresponding labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row\n",
    "        The `compute_rowSpecWindowing` function takes a row of data as input and processes the audio file\n",
    "    specified in the row to generate spectrogram windows. Here is a breakdown of the parameters used in\n",
    "    the function:\n",
    "    clean, optional\n",
    "        The `clean` parameter in the `compute_rowSpecWindowing` function is used to determine whether to\n",
    "    remove silence from the beginning and end of the audio signal before processing it. If `clean=True`,\n",
    "    the function will apply `librosa.effects.trim(y)` to remove the silence. If `\n",
    "    smoothAudio, optional\n",
    "        The `smoothAudio` parameter in the `compute_rowSpecWindowing` function is used to determine whether\n",
    "    to apply smoothing to the audio signal before generating the spectrogram. If `smoothAudio` is set to\n",
    "    `True`, the function will call a `smooth_audio` function with a smoothing factor of\n",
    "    smoothSpec, optional\n",
    "        The `smoothSpec` parameter in the `compute_rowSpecWindowing` function is used to determine whether\n",
    "    to apply smoothing to the spectrogram image generated from the audio data. If `smoothSpec` is set to\n",
    "    `True`, then the spectrogram image will be smoothed using the `smooth_image`\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        The code snippet is defining a function `compute_rowSpecWindowing` that processes audio data from a\n",
    "    DataFrame row. It loads an audio file, trims silence if specified, applies smoothing to the audio\n",
    "    and spectrogram if specified, generates a spectrogram image, and then performs windowing on the\n",
    "    spectrogram image. Finally, it creates a numpy array `y` with the 'Id_Persona\n",
    "    \n",
    "    '''\n",
    "    try:\n",
    "        y, sr = librosa.load(f\"..\\\\audios_modelo\\\\{row['Audio']}\")\n",
    "    except:\n",
    "        y, sr = librosa.load(f\"../audios_modelo/{row['Audio']}\")\n",
    "    \n",
    "\n",
    "    if silence : y = removeSilence(y)    \n",
    "    \n",
    "    \n",
    "    if filter: y = lowPassFilter(y, sr)\n",
    "\n",
    "\n",
    "\n",
    "    image = spec(y, sr, spec=specType)\n",
    "    print(image.shape)\n",
    "    if smoothSpec : image = smooth_image(image, 1.5)\n",
    "    \n",
    "    windows = windowing(image, 21000, despl = despl)\n",
    "    y = np.array([row['Id_Persona'] for i in range(21000)])\n",
    "    \n",
    "    return windows, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarModelo():\n",
    "    '''The function `entrenarModelo` evaluates different machine learning models using various\n",
    "    spectrogram types and returns classification reports for each model and spectrogram type.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        The function 'entrenarModelo' is returning a dictionary `classification_reports` containing\n",
    "    classification reports for different models and spectrogram types. Each model is evaluated with\n",
    "    different spectrogram types ('linear', 'log', 'mel', 'cqt', 'wavelet'). The classification reports\n",
    "    include metrics such as precision, recall, F1-score, and support for each class.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        #\"GradientBoosting\": GradientBoostingClassifier(),\n",
    "        #\"XGBoost\": XGBClassifier(),\n",
    "        #\"LightGBM\": LGBMClassifier(),\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "\n",
    "\n",
    "    classification_reports = {}\n",
    "    for model_name, model in models.items():\n",
    "        classification_reports[model_name] = {}\n",
    "\n",
    "        data = df.apply(lambda row: compute_rowSpecWindowing(row, specType='mel',despl=0,  filter=True, silence=True), axis=1)\n",
    "\n",
    "        X, y = unzipData(data)\n",
    "\n",
    "        X = np.reshape(X, (X.shape[0] * X.shape[1], X.shape[2]))\n",
    "        y = np.reshape(y, (y.shape[0] * y.shape[1]))\n",
    "\n",
    "        y = y[np.mean(X, axis=1) != 0]\n",
    "        X = X[np.mean(X, axis=1) != 0]\n",
    "\n",
    "        sc =StandardScaler()\n",
    "\n",
    "        X = sc.fit_transform(X)\n",
    "\n",
    "        joblib.dump(sc, '../raspi/modelos/StandardScaler.pkl')\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        joblib.dump(model, '../raspi/modelos/ModeloWindowing.pkl')\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "                'Model': 'rf',\n",
    "                'filter': True,\n",
    "                'silence': True,\n",
    "                'Accuracy': report,\n",
    "                \n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 6957)\n",
      "(128, 6869)\n",
      "(128, 5529)\n",
      "(128, 20964)\n",
      "(128, 1967)\n"
     ]
    }
   ],
   "source": [
    "resultados = entrenarModelo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(algorithm='windowing', dataType='ruido', model='rf', filter=False, audio='aux.mp3'):\n",
    "    \"\"\"\n",
    "    Predicts the output based on the given parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - algorithm (str): The algorithm to use for prediction. Default is 'windowing'.\n",
    "    - dataType (str): The type of data to use for prediction. Default is 'ruido'.\n",
    "    - model (str): The model to use for prediction. Default is 'svm'.\n",
    "    - filter (bool): Whether to apply a filter or not. Default is False.\n",
    "    - audio (str): The path to the audio file. Default is 'aux.mp3'.\n",
    "\n",
    "    Returns:\n",
    "    - y_pred (numpy.ndarray): The predicted output.\n",
    "\n",
    "    Raises:\n",
    "    - FileNotFoundError: If the audio file does not exist.\n",
    "    - ValueError: If the combination of algorithm, dataType, and model is not supported.\n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.exists(audio):\n",
    "        return -1\n",
    "    \n",
    "    if algorithm == 'windowing':\n",
    "        if model != 'rf':\n",
    "            return -1\n",
    "        \n",
    "        t0 = time.time()\n",
    "        \n",
    "        \n",
    "        m = joblib.load(f'../raspi/modelos/{dataType}/{algorithm}/ModeloWindowing.pkl')\n",
    "        scaler = joblib.load(f'../raspi/modelos/{dataType}/{algorithm}/StandardScaler.pkl')\n",
    "        \n",
    "        y, sr = librosa.load(audio)\n",
    "        \n",
    "        if dataType == 'ruidoNorm':\n",
    "            average_rms = joblib.load(f'./modelos/{dataType}/average_rms.pkl')\n",
    "            y = normalize_audio(y, average_rms)\n",
    "            y = apply_compression(y)\n",
    "        \n",
    "        y = lowPassFilter(y, sr)\n",
    "        y = removeSilence(y, 0.01)\n",
    "        image = spec(y, sr, spec='mel')\n",
    "        windows = windowing(image, 320, despl=0)\n",
    "        X = windows[np.mean(windows, axis=1) != 0]\n",
    "        X = scaler.transform(X)\n",
    "        y_pred = m.predict(X)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return y_pred, np.bincount(y_pred).argmax()\n",
    "    \n",
    "    if algorithm == 'specsModel':\n",
    "        if filter and dataType == 'ruidoNorm':\n",
    "            return -1\n",
    "        if model != 'cnn':\n",
    "            return -1\n",
    "        \n",
    "        model = joblib.load(f'./modelos/{dataType}/{algorithm}/modelos/cnn_{algorithm}_filter_{str(filter)}.pkl')\n",
    "        y, sr = librosa.load(audio)\n",
    "        \n",
    "        if dataType == 'ruidoNorm':\n",
    "            average_rms = joblib.load(f'./modelos/{dataType}/average_rms.pkl')\n",
    "            y = normalize_audio(y, average_rms)\n",
    "            y = apply_compression(y)\n",
    "        \n",
    "        y = removeSilence(y, 0.01)\n",
    "        y = lowPassFilter(y, sr)\n",
    "        y, sr = extrapolate_audio(y, sr, 6)\n",
    "        image = spec(y, sr, spec='wavelet')\n",
    "        \n",
    "        size = {'original': 32, 'ruido': 128, 'ruidoNorm': 256}[dataType]\n",
    "        \n",
    "        test = np.zeros((size, image.shape[0], image.shape[1]))\n",
    "        test[0] = image\n",
    "        y_pred = model.predict(test)\n",
    "        return y_pred[0]\n",
    "    \n",
    "    if algorithm == 'featureModel':\n",
    "        if model not in ['svc', 'lr', 'rf']:\n",
    "            return -1\n",
    "        \n",
    "        model = joblib.load(f'./modelos/{dataType}/{algorithm}/modelos/{model}_{algorithm}_filter_{str(filter)}.pkl')\n",
    "        scaler = joblib.load(f'./modelos/{dataType}/{algorithm}/scalers/scaler_{algorithm}_filter_{str(filter)}.pkl')\n",
    "        y, sr = librosa.load(audio)\n",
    "        \n",
    "        if dataType == 'ruidoNorm':\n",
    "            average_rms = joblib.load(f'./modelos/{dataType}/average_rms.pkl')\n",
    "            y = normalize_audio(y, average_rms)\n",
    "            y = apply_compression(y)\n",
    "        \n",
    "        y = lowPassFilter(y, sr)\n",
    "        y = removeSilence(y, 0.02)\n",
    "        features = extract_features(y, sr)\n",
    "        features = np.array(features).reshape(1, -1)\n",
    "        features = scaler.transform(features)\n",
    "        y_pred = model.predict(features)\n",
    "        return y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([4, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0,\n",
      "       2, 2, 4, 4, 0]), 0)\n"
     ]
    }
   ],
   "source": [
    "res  = predict(audio='../01_Gerard.mp3')\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
